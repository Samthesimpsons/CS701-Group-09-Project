{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If Google Colab\n",
    "# !git clone https://github.com/Samthesimpsons/CS701-Group-09-Project.git\n",
    "# !pip3 install -r /content/CS701-Group-09-Project/requirements.txt\n",
    "# !rm -rf /content/CS701-Group-09-Project/data\n",
    "# !unzip /content/CS701-Group-09-Project/data.zip -d /content/CS701-Group-09-Project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\samue\\\\OneDrive\\\\Desktop\\\\CS701-Group-09-Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from src.data_processing.visualization import (\n",
    "    process_training_ct_scan_metadata,\n",
    "    process_test_ct_scan_metadata,\n",
    "    visualize_segmentation_from_numpy_arrays,\n",
    "    generate_sweetviz_report,\n",
    ")\n",
    "from src.data_processing.preprocessing import (\n",
    "    apply_preprocessing_to_input_image,\n",
    "    apply_preprocessing_to_label_mask,\n",
    "    get_bounding_boxes,\n",
    ")\n",
    "\n",
    "from src.data_processing.loader import SAMSegmentationDataset, create_dataloader\n",
    "from src.modeling.trainer import SAMTrainer\n",
    "from src.modeling.inference import run_SAM_inference_and_save_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = process_training_ct_scan_metadata(\n",
    "    train_images_directory=\"data/train_images/\",\n",
    "    train_labels_directory=\"data/train_labels/\",\n",
    "    spacing_file_path=\"data/metadata/spacing_mm.txt\",\n",
    ")\n",
    "\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = process_test_ct_scan_metadata(\n",
    "    test_images_directory=\"data/test_images/\",\n",
    "    spacing_file_path=\"data/metadata/spacing_mm.txt\",\n",
    ")\n",
    "\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"data/train_images/33/15.png\", cv2.IMREAD_GRAYSCALE)\n",
    "mask = cv2.imread(\"data/train_labels/33/15.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "visualize_segmentation_from_numpy_arrays(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_sweetviz_report(\n",
    "#     train_data, report_filename=\"results/EDA/train_data_EDA_report.html\"\n",
    "# )\n",
    "\n",
    "# generate_sweetviz_report(\n",
    "#     test_data, report_filename=\"results/EDA/test_data_EDA_report.html\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_image_sample = apply_preprocessing_to_input_image(image)\n",
    "\n",
    "bounding_boxes_dict = get_bounding_boxes(mask, \"33\", 15)\n",
    "\n",
    "list_of_bounding_boxes = [\n",
    "    bounding_box for _, bounding_box in bounding_boxes_dict.items()\n",
    "]\n",
    "\n",
    "visualize_segmentation_from_numpy_arrays(\n",
    "    processed_image_sample, mask, list_of_bounding_boxes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = \"wanglab/medsam-vit-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SAMSegmentationDataset(\n",
    "    image_dir=\"data/train_images\",\n",
    "    mask_dir=\"data/train_labels\",\n",
    "    spacing_metadata_dir=\"data/metadata/spacing_mm.txt\",\n",
    "    processor=pretrained_model_name,\n",
    ")\n",
    "\n",
    "print(f\"Number of records: {len(train_dataset)}\")\n",
    "print(f\"Example of one record:\")\n",
    "for k, v in train_dataset[0].items():\n",
    "    print(f\"{k}: {v.shape}\")\n",
    "\n",
    "test_dataset = SAMSegmentationDataset(\n",
    "    image_dir=\"data/test_images\",\n",
    "    bbox_file_dir=\"data/metadata/test1_bbox.txt\",\n",
    "    spacing_metadata_dir=\"data/metadata/spacing_mm.txt\",\n",
    "    processor=pretrained_model_name,\n",
    ")\n",
    "\n",
    "print(\"\\n====================\\n\")\n",
    "print(f\"Number of records: {len(test_dataset)}\")\n",
    "print(f\"Example of one record:\")\n",
    "for k, v in test_dataset[0].items():\n",
    "    try:\n",
    "        print(f\"{k}: {v.shape}\")\n",
    "    except:\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "train_dataloader = create_dataloader(\n",
    "    train_dataset,\n",
    "    batch_size=36,\n",
    "    train_ratio=0.8,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "print(\"\\n====================\\n\")\n",
    "print(f\"Example of one batch:\")\n",
    "for k, v in batch.items():\n",
    "    print(f\"{k}: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SAMTrainer(\n",
    "    model_name=pretrained_model_name,\n",
    "    device=\"cpu\",  # Use GPU (cuda) if available\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.k_fold_cross_validation(\n",
    "#     dataloader=train_dataloader,  # SAM DataLoader object\n",
    "#     k_folds=5,  # Default: 5 folds\n",
    "#     num_epochs=10,  # Default: 10 epochs per fold\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_SAM_inference_and_save_masks(\n",
    "#     model=trainer.model,\n",
    "#     test_dataset=test_dataset,\n",
    "#     batch_size=1,\n",
    "#     device=\"cpu\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.imread(\"data/test_images/51/1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# mask = cv2.imread(\"data/test_labels/51/1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# mask = cv2.resize(mask, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "# mask = (mask > 0).astype(np.uint8)\n",
    "\n",
    "# visualize_segmentation_from_numpy_arrays(image, mask, [[274, 192, 313, 255]], from_inference=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
