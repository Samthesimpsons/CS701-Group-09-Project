{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If Google Colab\n",
    "# !git clone https://github.com/Samthesimpsons/CS701-Group-09-Project.git\n",
    "# !pip3 install -r /content/CS701-Group-09-Project/requirements.txt\n",
    "# !rm -rf /content/CS701-Group-09-Project/data\n",
    "# !rm -rf /content/sample_data\n",
    "# !unzip /content/CS701-Group-09-Project/data.zip -d /content/CS701-Group-09-Project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.chdir(\"/content/CS701-Group-09-Project\")\n",
    "os.chdir(\"C:\\\\Users\\\\samue\\\\OneDrive\\\\Desktop\\\\CS701-Group-09-Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from google.colab import files\n",
    "from src.visualization import (\n",
    "    process_training_ct_scan_metadata,\n",
    "    process_test_ct_scan_metadata,\n",
    "    visualize_segmentation_from_numpy_arrays,\n",
    "    generate_sweetviz_report,\n",
    ")\n",
    "from src.loader import SAMSegmentationDataset, create_dataloader\n",
    "from src.trainer import SAMTrainer\n",
    "from src.inference import run_SAM_inference_and_save_masks\n",
    "from src.utils import get_latest_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = process_training_ct_scan_metadata(\n",
    "#     train_images_directory=\"data/train_images/\",\n",
    "#     train_labels_directory=\"data/train_labels/\",\n",
    "#     spacing_file_path=\"data/metadata/spacing_mm.txt\",\n",
    "# )\n",
    "\n",
    "# train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = process_test_ct_scan_metadata(\n",
    "#     test_images_directory=\"data/test_images/\",\n",
    "#     spacing_file_path=\"data/metadata/spacing_mm.txt\",\n",
    "# )\n",
    "\n",
    "# test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"data/train_images/33/15.png\", cv2.IMREAD_GRAYSCALE)\n",
    "mask = cv2.imread(\"data/train_labels/33/15.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "visualize_segmentation_from_numpy_arrays(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_sweetviz_report(\n",
    "#     train_data, report_filename=\"results/EDA/train_data_EDA_report.html\"\n",
    "# )\n",
    "\n",
    "# generate_sweetviz_report(\n",
    "#     test_data, report_filename=\"results/EDA/test_data_EDA_report.html\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = \"wanglab/medsam-vit-base\"\n",
    "\n",
    "train_dataset = SAMSegmentationDataset(\n",
    "    image_dir=\"data/train_images\",\n",
    "    mask_dir=\"data/train_labels\",\n",
    "    spacing_metadata_dir=\"data/metadata/spacing_mm.txt\",\n",
    "    processor=pretrained_model_name,\n",
    ")\n",
    "\n",
    "print(f\"Number of records: {len(train_dataset)}\")\n",
    "print(f\"Example of one record:\")\n",
    "for k, v in train_dataset[33].items():\n",
    "    try:\n",
    "        print(f\"{k}: {v.shape}\")\n",
    "    except:\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "test_dataset = SAMSegmentationDataset(\n",
    "    image_dir=\"data/test_images\",\n",
    "    bbox_file_dir=\"data/metadata/test1_bbox.txt\",\n",
    "    spacing_metadata_dir=\"data/metadata/spacing_mm.txt\",\n",
    "    processor=pretrained_model_name,\n",
    ")\n",
    "\n",
    "print(\"\\n====================\\n\")\n",
    "print(f\"Number of records: {len(test_dataset)}\")\n",
    "print(f\"Example of one record:\")\n",
    "for k, v in test_dataset[33].items():\n",
    "    try:\n",
    "        print(f\"{k}: {v.shape}\")\n",
    "    except:\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "train_dataloader = create_dataloader(\n",
    "    train_dataset,\n",
    "    batch_size=3,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "print(\"\\n====================\\n\")\n",
    "print(f\"Example of one batch:\")\n",
    "for k, v in batch.items():\n",
    "    print(f\"{k}: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SAMTrainer(\n",
    "    model_name=pretrained_model_name,\n",
    "    device=\"cpu\",\n",
    "    learning_rate=1e-5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.k_fold_cross_validation(\n",
    "    dataloader=train_dataloader,\n",
    "    k_folds=10,\n",
    "    num_epochs=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_model_path = get_latest_model_path('models/')\n",
    "\n",
    "root_model_path, base_model_path = latest_model_path.split(\"/\")\n",
    "\n",
    "shutil.make_archive(latest_model_path, \"zip\", root_dir=root_model_path, base_dir=base_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_SAM_inference_and_save_masks(\n",
    "    model=trainer.model,\n",
    "    test_dataset=test_dataset,\n",
    "    batch_size=1,\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"data/test_images/51/25.png\", cv2.IMREAD_GRAYSCALE)\n",
    "mask = cv2.imread(\"data/test_labels/51/25.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "visualize_segmentation_from_numpy_arrays(\n",
    "    image,\n",
    "    mask,\n",
    "    [\n",
    "        [299, 129, 444, 369],\n",
    "        [308, 141, 362, 214],\n",
    "        [110, 204, 332, 313],\n",
    "        [219, 182, 283, 238],\n",
    "        [263, 214, 309, 249],\n",
    "        [183, 205, 230, 247],\n",
    "        [192, 308, 248, 360],\n",
    "        [116, 146, 217, 240],\n",
    "    ],\n",
    "    from_inference=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.make_archive(\"data/test_labels\", \"zip\", root_dir=\"data\", base_dir=\"test_labels\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
