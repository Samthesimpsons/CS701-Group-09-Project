{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "from loguru import logger\n",
    "\n",
    "DATA_DIR = os.path.join(\n",
    "    Path().resolve().parent.parent,\n",
    "    'data', 'formatted'\n",
    ")\n",
    "\n",
    "x_train_dir = os.path.join(DATA_DIR, \"train_images\")\n",
    "y_train_dir = os.path.join(DATA_DIR, \"train_labels\")\n",
    "\n",
    "x_val_dir = os.path.join(DATA_DIR, \"val_images\")\n",
    "y_val_dir = os.path.join(DATA_DIR, \"val_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalImageDataset(Dataset):\n",
    "    # Your Dataset class code here\n",
    "    CLASSES = [\n",
    "        \"background\",\n",
    "        \"gallbladder\",\n",
    "        \"stomach\",\n",
    "        \"esophagus\",\n",
    "        \"right kidney\",\n",
    "        \"right adrenal gland\",\n",
    "        \"left adrenal gland\",\n",
    "        \"liver\",\n",
    "        \"left kidney\",\n",
    "        \"aorta\",\n",
    "        \"spleen\",\n",
    "        \"inferior vena cava\",\n",
    "        \"pancreas\"\n",
    "    ]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        images_dir,\n",
    "        masks_dir,\n",
    "        classes=None\n",
    "    ):\n",
    "        self.ids = os.listdir(images_dir)\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
    "\n",
    "        # Convert class names to class values\n",
    "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "            # read image and mask\n",
    "            image = sitk.GetArrayFromImage(\n",
    "                sitk.ReadImage(self.images_fps[i])\n",
    "            )\n",
    "            mask = sitk.GetArrayFromImage(\n",
    "                sitk.ReadImage(self.masks_fps[i])\n",
    "            )\n",
    "\n",
    "            label_mapping = {v: i for i, v in enumerate(self.class_values)}\n",
    "            mask = np.vectorize(label_mapping.get)(mask).astype(np.int64)\n",
    "\n",
    "            # add a channel dimension to the image - shape (1, H, W)\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            image = torch.from_numpy(image).float()\n",
    "            mask = torch.from_numpy(mask).long()\n",
    "\n",
    "            return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        \"\"\"\n",
    "        outputs: tensor of shape (N, C, H, W) where C = number of classes\n",
    "        targets: tensor of shape (N, H, W) with class indices (0 <= target <= C-1)\n",
    "        \"\"\"\n",
    "        \n",
    "        num_classes = outputs.size(1)\n",
    "        # Convert targets to one-hot encoding\n",
    "        targets_one_hot = torch.nn.functional.one_hot(targets, num_classes).permute(0, 3, 1, 2).float()\n",
    "        \n",
    "        # Apply softmax to outputs to get probabilities\n",
    "        outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        \n",
    "        # Calculate Dice coefficient per class\n",
    "        intersection = (outputs * targets_one_hot).sum(dim=(2, 3))\n",
    "        union = outputs.sum(dim=(2, 3)) + targets_one_hot.sum(dim=(2, 3))\n",
    "        dice_score = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
    "        \n",
    "        # Average over batch and classes\n",
    "        dice_loss = 1.0 - dice_score.mean()\n",
    "        \n",
    "        return dice_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.inf  # Initialize with infinity\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss  # We aim to minimize validation loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0  # Reset counter if validation loss improves\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decreases.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.add(\"training.log\", format=\"{time} {level} {message}\", level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\n",
    "    \"background\",\n",
    "    \"gallbladder\",\n",
    "    \"stomach\",\n",
    "    \"esophagus\",\n",
    "    \"right kidney\",\n",
    "    \"right adrenal gland\",\n",
    "    \"left adrenal gland\",\n",
    "    \"liver\",\n",
    "    \"left kidney\",\n",
    "    \"aorta\",\n",
    "    \"spleen\",\n",
    "    \"inferior vena cava\",\n",
    "    \"pancreas\"\n",
    "]\n",
    "train_dataset = MedicalImageDataset(\n",
    "    x_train_dir,\n",
    "    y_train_dir,\n",
    "    classes=CLASSES,\n",
    ")\n",
    "val_dataset = MedicalImageDataset(\n",
    "    x_val_dir,\n",
    "    y_val_dir,\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keithchiang/opt/miniconda3/envs/unet/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet50\",    \n",
    "    encoder_weights=None,\n",
    "    in_channels=1,\n",
    "    classes=len(CLASSES),\n",
    ")\n",
    "\n",
    "loss_fn = smp.losses.DiceLoss(mode='multiclass')\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.encoder.parameters(), 'lr': 1e-4},\n",
    "    {'params': model.decoder.parameters(), 'lr': 1e-3},\n",
    "    {'params': model.segmentation_head.parameters(), 'lr': 1e-3}\n",
    "])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, verbose=True)\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=5, \n",
    "    verbose=True, \n",
    "    delta=0.001, \n",
    "    path='best_model.pth', \n",
    "    trace_func=logger.info\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Training]:   0%|          | 2/1676 [00:10<2:23:31,  5.14s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[1;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 29\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     32\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/unet/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/unet/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/unet/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize metrics storage\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_dice_scores = []\n",
    "val_dice_scores = []\n",
    "\n",
    "num_epochs = 20\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define evaluation metric\n",
    "loss_fn = DiceLoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_dice = 0.0\n",
    "\n",
    "    for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\"):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, masks)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "\n",
    "        # Calculate Dice coefficient for logging\n",
    "        with torch.no_grad():\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            dice = 1 - loss_fn(outputs, masks).item()\n",
    "            train_dice += dice * images.size(0)\n",
    "\n",
    "    train_loss /= len(train_dataset)\n",
    "    train_dice /= len(train_dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    train_dice_scores.append(train_dice)\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_dice = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\"):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, masks)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Calculate Dice coefficient for logging\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            dice = 1 - loss_fn(outputs, masks).item()\n",
    "            val_dice += dice * images.size(0)\n",
    "\n",
    "    val_loss /= len(val_dataset)\n",
    "    val_dice /= len(val_dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    val_dice_scores.append(val_dice)\n",
    "\n",
    "    # Logging\n",
    "    logger.info(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    logger.info(f\"Training Loss: {train_loss:.4f}, Training Dice Coefficient: {train_dice:.4f}\")\n",
    "    logger.info(f\"Validation Loss: {val_loss:.4f}, Validation Dice Coefficient: {val_dice:.4f}\")\n",
    "\n",
    "    # Scheduler step\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        logger.info(\"Early stopping triggered. Stopping training.\")\n",
    "        break\n",
    "\n",
    "# Load the best model after training\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "logger.info(\"Training complete. Best model loaded.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
